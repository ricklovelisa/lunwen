文本挖掘技术研究

3 文本挖掘技术研究
3.1 文本分类技术研究

	

3.1.1 文本分类任务
	文本分类任务简单的描述为如下映射：
	A -> B
	A为未标注类别的输入文本集合，B为输出类别集合又称A在对应类别中的映射，->为分类器分类过程。

3.1.2 文本分类过程
	文本分类器训练流程如下：

	原始训练文本 -> 文本预处理 -> 文本结构化 -> [文本分类器训练 -> 分类器模型参数调优] -> 分类器性能测试并择优选取 -> 分类器工程化并集成至指定系统 -> 模型日常维护

	文本分类器分类流程如下
	未标注的待分类文本 -> 文本预处理 -> 文本结构化 -> 输入分类器分类 -> 输出类别标注


	##########################################################################################
	原始训练文本 -> 文本清理 -> 分词/去停用词 -> 特征选择 -> 权重计算 -> 构建空间向量模型 -> [文本分类器训练 -> 分类器模型参数调优] -> 分类器性能测试并择优选取 -> 分类器工程化并集成至指定系统 -> 模型日常维护

	文本分类器分类流程如下
	未标注的待分类文本 -> 文本清理 -> 分词/去停用词 -> 特征选择 -> 权重计算 -> 构建空间响亮模型 -> 输入分类器分类 -> 输入类别标注
	##########################################################################################


3.1.3文本结构化
	  文本结构化又称文本向量化，是文本分类任务中最为重要的一个环节。
	  文本结构化的目的是让非结构化的文本数据在尽可能的减少信息损失的情况下转化为计算机可以识别并计算的数据格式。一下将对文本结构化过程中的几个重要步骤进行展开。

	  3.1.3.1 文本表示
		  	  文本结构化最重要的目标就是将文本表示为计算机可以理解并且运算的数据形式。
		  	  现在主要有三种文本表示模型：
		  	  a.概率模型
			  b.代数论模型
	  		  c.集合论模型

		  	  其中代数论中的向量空间模型是应用最广泛的文本表示模型。其由XXXX#需要提供参考文献#提出，并且广泛应用于信息检索领域，并且取得了不错的效果。		  		
		  
	  3.1.3.2 最小语言特征单元提取
		  		  
		  	  最小语言特征单元（以下简称特征单元）提取主要要目的是从文本中抽取出尽可能小，包含尽可能多信息的粒度单元。在中文文本处理中，这个过程又称为分词。

		  	  在文本挖掘的兴起的英语世界，特征单元字面上就是英文单词，与之所对应的是中文的词，而中文不像英语每个单词都是独立不可再分的，换而言之相对与英文单词，中文的单词没有明确的边界。

		  	  中文中特征单元粒度最小的是单字，虽然其足够小，能够最大程度上减小稀疏数据的产生，但是其所包含的语言信息太少，并不符合上述分词的要求。但是近期也有国外学者对中文文本分类做了部分研究，提出了根据单字构造空间向量模型，并且将其应用至亚马逊买家评论以及文本分类，并提高了准确度[1]《Text Understanding from Scratch》arXiv:1502.01710v1 [cs.LG] 5 Feb 2015。

		      值得一提的是，李景阳[2]在《文本分类中的特征选择与权重计算》中提到，特征单元维数在50000以上时，二字串的分词性能更加优良。但是考虑本文的应用场景是针对新闻资讯系统，每天更新的文章数量有限，相对于样本数量，维数过大会造成统计学中的维度灾难，同时会造成模型的过拟合，反而会降低分类器的性能。

		  	  现有的中文分词工具有如下：

		  	  ##艳萍做的表格##

		  	  本文对分词不做过多讨论，使用的分词工具是基于jieba分词的jiebaR。

		  	  分词得到的语言最小单元在一般情况下，数量为会非常的大。其中包含了大量的噪音，在之后的工作之前需要对分词结果进行一轮粗略的清理，目的是清除例如“的”这类广泛存在于文本中，却又没有实际含义的词。这类词被称作为停用词。现如今已经有许多前人总结出了中文中的一些停用次，本文中用到的停用词整合了哈工大停用词表、四川大学机器智能实验室停用词库、百度停用词表。

	  3.1.3.3 特征选择
		  	  特征选择是对分词结果进行降维的过程，在分词并且去除停用词之后进行。一般来说，每一个分类器都需要进行特征选择，目的是进一步减少特征单元的数量，降低计算压力，提升分类器性能。

		  	  一般来说有如下特征选择的方法：
		  	  a.文档频度(df)
      		  文档频度是最为传统的特征选择方法，但是大量实验表明，文档频度有着出人意料的效果，对于提升分类器性能，降低计算压力效果较好。本文将采取df > 2的方式对语料统一截断并降维。
		  	  b.卡方检验(chisq test)
		  	  卡方检验源自统计学，其意义是度量某一变量与另一变量的相关程度，是为显著性检验。其一般形式计算公式为：
		  	  # 数学公式 #
		  	  由于其同时考虑的正例和负例，具有较强的现实意义。并且其是特征选择性能最为优良的指标之一。《文本分类中的特征选择与权重计算》[1,48,52]
		  	  c.互信息
		  	  	互信息源于信息论，描述了一个随机变量中包含的关于另一个随机变量的信息量这样一个指标。其数学公式为：
		  			# 数学公式 #
		  	 	互信息在文本特征为度筛选是也有广泛的应用，在本文中，不做考虑。
		  	  d.信息增益(information gain)
		  	  	信息增益同样来自信息论。其最典型的特征是非对称的，即P对Q的增益量Q不等于Q对P的增益量。其数学公式如下：
		  	  		# 数学公式 #
		  	  	广泛的实验证明，IG同样是性能良好的特征维度删选指标之一，但较为偏向高频特征。《文本分类中的特征选择与权重计算》[1,52]
	  3.1.3.4 权重计算
	  		  常用的权重计算方式有三种:
	 		  a.布尔型
	  		  	布尔型是最基础的权重表示方式。如果类别ci存在特征ti，则wcti为1，否则，wcti为0。由于布尔权重会丢失大量的文本信息，所以在本文那种不对其作过多的描述和进一步的实验。
	  		  b.频度。词频(tf)
	  		  	词频是最常用的权重计算方式之一，源自统计学，定义为一个词在一篇文档中出现的频数。其认为，一个词在一篇文档中出现的频数越高，则其重要程度越重。由于计算方便，以及优良的分类性能，成为了工程实践中分类模型权重的不二之选。
	  		  c.TF-IDF（term frequency–inverse document frequency）
	  		  	TF-IDF源自于信息检索，描述词频高的词对于一个语料库的其中一个文件的重要程度。数学公式为：
	  		  		# 数学公式 #
	  		  	很明显，TF-IDF由两部分组成，词频tf和逆文档频度idf相乘。tf在b.已经讨论过，而idf主要描述一个词在逆向文档中的频度，主要考量一个词在一个特定的预料库中的重要程度。一般来说，词的TF越大则说明该词越重要，而IDF越大说明在语料库中该词分布月普遍，相对的重要性越低。在本文中，TF-IDF指标由于其特殊性——需要对整个预料进行计算，导致了工程实施上的障碍。对于新获取的待分类的文章，其中词汇的TF-IDF，应该与训练集中的词一同计算才能保证其准缺性，这样就导致了一个问题——每一次分类之前都需要重新计算一边权重，接着影响到模型的训练，这样会严重制约分类效率，并且不利于模型维护以及更新。所以在本文中，TF-IDF权重只会作为一个重要的实验参考对象，来评判其他权重的分类性能。



3.1.4 文本分类算法
	文本分类的算法模型大多基于传统的分类模型。在本问提到的新闻资讯系统中，类别是认为指定并且确定的。所以采用的是有监督的机器学习算法。
	从概率模型的角度来说，常用的有监督的机器学习算法主要有两种：
		a.基于概率的产生式模型(generative model)[《文本分类中的特征选择与权重计算》]，其主要代表有朴素贝叶斯模型，高斯模型，贝叶斯网络等，限于本文的应用场景，除了朴素贝叶斯模型外，其他模型不做过多的阐述和介绍。
		朴素贝叶斯模型已著名的贝叶斯定理为基础，在文本分类中可以描述为
		P( Category | Document) = P ( Document | Category ) * P( Category) / P(Document)
		遵循经验风险最小原则，其鲜明的特点是运用了：先验知识（先验概率）以及模型可以增量式学习[《文本分类中的特征选择与权重计算》]，但是由于贝叶斯定理的一个前提假设，变量之间必须满足独立性原则，使其在文本挖掘中缺乏足够的理论支持。因为文本中的词不是相互独立的，其间包含了语义关系。同时，基于贝叶斯理论的模型需求大量的训练集，以寻求更加逼近真实的概率分布。在少量样本的的情况下，其分类性能会大幅衰减。但是在实际使用中，朴素贝叶斯的效果是值得称道的，在本文中，朴素贝叶斯是一个待测试的分类算法。

		b.判别模型，也称非参数模型。其理论基础源自于统计学习理论，提出了结构风险最小的思想。典型代表是SVM，逻辑回归等。

		SVM模型的思想为将现有维度下不可分的问题映射到高维再进行分类，从而解决当前维度下类别不可分的问题。其中距离分类界限最近的向量，被称为支持向量。#SVM分类图例一张#
		在一般的传统统计模型中，关注的点在于经验风险最小，这使得传统模型面临一个问题，就是过拟合和不可扩展。为了解决这个问题，SVM模型于上个世纪被踢出，其考量的是结构风险的最小化。这个特性使得其具有较好的泛化能力。
		SVM的理论较为深刻，而在本文的背景下，更多的是应用场景，对其理论描述不做过多的讨论。其中的参数着重于核函数、gamma和损失函数cost。在试验中，将其设置为如下范围进行考量。
    	其中核函数备选两个：线性核函数和高斯核函数。
    	gamma取值范围10^-6到10^-1
    	cost取值范围为10^-2到10^2

		本文将着重对SVM进行阐述和分析，并且在实验中作为被试，对比如其他分类算法。

		c.值得一提的是，本文背景中还有一个已经使用了的分类模型，基于关键词的匹配分类模型。其理论基础非常简单。即每一个类别中都有相应的关键词，在分类过程中，对文章的标题进行关键词的匹配，标题中出现了类别关键词的即被判为这一类别。这个模型可以看作是路透社专家分类的简化版，其分类规则约减为关键词。而制约这个分类算法性能的是关键词的质量、匹配的对象。

		在本文应用场景中，关键词来源于idf算法的关键词抽取，即对每一个类别的文本中的词均计算idf，统计整合其中词频较高的，同时人工干预，剔除一些过于宽泛的词，保留类别辨识度较高的词；类别间的距离较小，隶属于IT行业下的二级或者三级分类，甚至有的仅仅是话题，而关键词匹配却有着出乎意料的分类效果；在本人经过大量试验后发现，对于关键词匹配的分类，基于文章标题的匹配效果是最好的，原因在于新闻中，文章标题大多都已经包含了该新闻所属的类别信息。而文章内容对于匹配来说有着太多的不确定性，会使类别匹配过于杂乱。

		本文对这个算法的效果和SVM以及朴素贝叶斯进行比较。

3.1.5 文本分类性能指标
	文本分类指标参考的是信息论中的命中率。
	用2X2矩阵表示为
	# 命中矩阵 #
	其中 被称为TP，表示正确命中。
	为FP，表示错误命中。
	为TN，表示正确未命中
	为FN，表示错误未命中

	本文中需要关注的两个指标是准确率和召回率。来自于信息检索理论。
	同时还有F-measure，这个指标同时考虑了准确率和召回率，本文将引入准确率和召回率的ROC曲线，尽心可视化的分类器性能比较。

3.2 情感分析研究

3.2.1 情感分析种类
	  a.基于词典的情感分析
	  	这是比较传统的情感分析方法，其关键是对于情感词的人工删选和标注。这也是本文所关注的情感分析方向。
	  b.基于机器学习的分类
	  	只是现在比较常用的情感分析方法，其把情感分析转化为分类问题，进而用机器学习的方法来解决问题。其优点和上述文本分类中的有点相同，但同样的，其缺点在于泛化能力受到训练集的制约。在本文文本分类的基础上，将不对这种方法做过多的讨论。
3.2.2 情感分析流程
	  与大部分文本挖掘流程相似，在正式分析之前，都需要进过文本的预处理，流程如下：

	  待分析文本 -> 文本预处理 -> 文本结构化 -> 情感分析 -> 输出情感分析结果

	  对于非机器学习的情感分析部分还能继续细化为：

	  情感信息抽取 -> 情感信息权重计算 -> 情感信息权重汇总 -> 输出情感结构

	  其中情感信息的抽取是最为底层也是相对重要的工作，一般的大多基于情感词典来完成。

	  情感信息权重计算是表征文档情感的重要部分，现有的算法包括：

	  基于PMI的情感计算：

	  基于贝叶斯理论的情感概率计算：

3.2.3 情感分析算法
	  在本文中，情感分析算法主要基于贝叶斯理论。
	  首先计算一篇文章中所有情感词在情感词典中的先验得分，公式如下:
	  |tf*log(count/total)|
	  接着计算每一篇文章中，每一个情感的后验得分
	  |log(score*prior/count)|
	  最终两者加和取最大值所对应的情感即为这篇文章的情感。
	  同理计算极性的得分。

	  示例如下：

3.3 小结

	文本分类和情感分析的种类繁多，各种算法的性能也不尽相同。本文在接下来的第五张将会着重对文本分类进行实验，并且根据性能指标对每一个分类算法进行评判和比较，挑选出最优的酸饭用于实际的系统中。


