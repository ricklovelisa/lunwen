文本分类研究

3 文本分类研究
3.1 文本分类概述
	文本分类指对大量文本根据某一维度，对其文本内容进行分类的过程。
	在机器学习兴起之前，文本分类工作主要有人工完成。例如路透社的专家分类。但是人工进行文本分类效率低下，并且错误率较高。在机器学习兴起之后，人们开始探索如何让机器代替人工进行繁重的分类任务，自动化文本分类诞生了。
	目前英文的自动化文本分类已经取得了丰富的成果，并且提出了许多算用于自动化文本分类。比较经典的有贝叶斯分类器、SVM分类器、KNN分类器、神经网络分类器等。
	

3.2 文本分类任务
	文本分类任务简单的描述为如下映射：
	A -> B
	A为未标注类别的输入文本集合，B为输出类别集合又称A在对应类别中的映射，->为分类器分类过程。

3.3 文本分类过程
	文本分类器训练流程如下：

	原始训练文本 -> 文本预处理 -> 文本结构化 -> [文本分类器训练 -> 分类器模型参数调优] -> 分类器性能测试并择优选取 -> 分类器工程化并集成至指定系统 -> 模型日常维护

	文本分类器分类流程如下
	未标注的待分类文本 -> 文本预处理 -> 文本结构化 -> 输入分类器分类 -> 输出类别标注


	##########################################################################################
	原始训练文本 -> 文本清理 -> 分词/去停用词 -> 特征选择 -> 权重计算 -> 构建空间向量模型 -> [文本分类器训练 -> 分类器模型参数调优] -> 分类器性能测试并择优选取 -> 分类器工程化并集成至指定系统 -> 模型日常维护

	文本分类器分类流程如下
	未标注的待分类文本 -> 文本清理 -> 分词/去停用词 -> 特征选择 -> 权重计算 -> 构建空间响亮模型 -> 输入分类器分类 -> 输入类别标注
	##########################################################################################



	3.3.1 文本结构化
		  文本结构化又称文本向量化，是文本分类任务中最为重要的一个环节。
		  文本结构化的目的是让非结构化的文本数据在尽可能的减少信息损失的情况下转化为计算机可以识别并计算的数据格式。一下将对文本结构化过程中的几个重要步骤进行展开。

		  3.3.1.1 文本表示
		  		  文本结构化最重要的目标就是将文本表示为计算机可以理解并且运算的数据形式。
		  		  现在主要有三种文本表示模型：
		  		  a.概率模型
		  		  b.代数论模型
		  		  c.集合论模型

		  		  其中代数论中的向量空间模型是应用最广泛的文本表示模型。其由XXXX#需要提供参考文献#提出，并且广泛应用于信息检索领域，并且取得了不错的效果。

		  		  

		  其中包括文本清理过程、分词、特征选择/抽取、权重计算和构建空间向量模型这些步骤。
		  
		  3.3.1.2 最小语言特征单元提取
		  		  
		  		  最小语言特征单元（以下简称特征单元）提取主要要目的是从文本中抽取出尽可能小，包含尽可能多信息的粒度单元。在中文文本处理中，这个过程又称为分词。

		  		  在文本挖掘的兴起的英语世界，特征单元字面上就是英文单词，与之所对应的是中文的词，而中文不像英语每个单词都是独立不可再分的，换而言之相对与英文单词，中文的单词没有明确的边界。

		  		  中文中特征单元粒度最小的是单字，虽然其足够小，能够最大程度上减小稀疏数据的产生，但是其所包含的语言信息太少，并不符合上述分词的要求。但是近期也有国外学者对中文文本分类做了部分研究，提出了根据单字构造空间向量模型，并且将其应用至亚马逊买家评论，并提高了准确度 #这里需要补充参考文献#。

		  		  值得一提的是，李景阳[1]在《文本分类中的特征选择与权重计算》中提到，特征单元维数在50000以上时，二字串的分词性能更加优良。但是考虑本文的应用场景是针对新闻资讯系统，每天更新的文章数量有限，相对于样本数量，维数过大会造成统计学中的维度灾难，同时也会造成模型的过拟合，反而会降低分类器的性能。

		  		  现有的中文分词工具有如下：

		  		  ##艳萍做的表格##

		  		  本文对分词不做过多讨论，使用的分词工具是基于jieba分词的jiebaR。

		  		  分词得到的语言最小单元在一般情况下，数量为会非常的大。其中包含了大量的噪音，在之后的工作之前需要对分词结果进行一轮粗略的清理，目的是清除例如“的”这类广泛存在于文本中，却又没有实际含义的词。这类词被称作为停用词。现如今已经有许多前人总结出了中文中的一些停用次，本文中用到的停用词整合了哈工大停用词表、四川大学机器智能实验室停用词库、百度停用词表。

		  3.3.1.3 特征选择
		  		  特征选择是对分词结果进行降维的过程，在分词并且去除停用词之后进行。一般来说，每一个分类器都需要进行特征选择，目的是进一步减少特征单元的数量，降低计算压力，提升分类器性能。

		  		  一般来说有如下

3.4 文本分类算法

3.5 文本分类性能指标
3.6 小结
	本文主要是对SVM、贝叶斯、传统分类模型的比较，以及将最优算法的工程化实现。